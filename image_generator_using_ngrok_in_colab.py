# -*- coding: utf-8 -*-
"""Image_generator using ngrok in colab.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xJ0Ps37zjNXp5IxnwRbKzkGzjmieeAa3

# Text to Image generator using Ngrok and streamlit in Google Colab

# 1- Installing libraries
"""

!pip install pyngrok

from pyngrok import ngrok

"""Go to [Ngrok website](https://ngrok.com/), make account and get auth token"""

!ngrok authtoken 2ljIyyLR9f0VtMUkUEchZ0zGeZS_6LkzgrqgURGyggZDUAazx  # Replace token with the actual token

!pip install diffusers torch torchvision streamlit  numpy huggingface-hub

!pip install -r /content/requirements_clean.txt  #In case if you want to install all libraries from requirement.txt instead of above code in notebook

!pip install pillow==10.4.0

"""# 2-Streamlit .py script"""

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app_1.py
# import streamlit as st
# from diffusers import DiffusionPipeline
# import torch
# from PIL import Image
# import io
# import numpy as np
# import time
# 
# @st.cache_resource
# def load_model():
#     model = DiffusionPipeline.from_pretrained("runwayml/stable-diffusion-v1-5")
#     model.to("cuda" if torch.cuda.is_available() else "cpu")
#     return model
# 
# generator = load_model()
# 
# st.title('Text to Image Generator')
# prompt = st.text_input("Enter your prompt:", "A scenic landscape painting")
# 
# if st.button('Generate Image'):
#     start_time = time.time()  # Start timing
#     with st.spinner('Generating image...'):
#         # Generate the image with a low number of inference steps
#         output = generator(prompt, num_inference_steps=5, eta=0.0)  # Adjust ETA to possibly reduce computation
#         image = output.images[0]
# 
#         # Convert to NumPy array
#         image = np.array(image)
# 
#         # Convert to PIL Image
#         pil_image = Image.fromarray(image.astype(np.uint8))  # Cast to uint8 for PIL compatibility
# 
#         # Display the image
#         st.image(pil_image, caption='Generated Image', use_column_width=True)
# 
#         # Provide a download button
#         buf = io.BytesIO()
#         pil_image.save(buf, format="JPEG")
#         byte_im = buf.getvalue()
#         st.download_button(
#             label="Download Image",
#             data=byte_im,
#             file_name="generated_image.jpg",
#             mime="image/jpeg"
#         )
# 
#     # Record and display time taken
#     end_time = time.time()
#     st.write(f"Time taken to generate image: {end_time - start_time:.2f} seconds")
# 
# st.write("Enter a textual prompt and press generate to create an image.")
#

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app_1.py
# import streamlit as st
# from diffusers import LDMTextToImagePipeline
# import torch
# from PIL import Image
# import io
# import numpy as np
# import time
# 
# @st.cache_resource
# def load_model():
#     model = LDMTextToImagePipeline.from_pretrained("CompVis/ldm-text2im-large-256")
#     model.to("cuda" if torch.cuda.is_available() else "cpu")
#     return model
# 
# generator = load_model()
# 
# st.title('Text to Image Generator')
# prompt = st.text_input("Enter your prompt:", "A scenic landscape painting")
# 
# if st.button('Generate Image'):
#     start_time = time.time()  # Start timing
#     with st.spinner('Generating image...'):
#         # Generate the image
#         output = generator([prompt], num_inference_steps=50)
#         image = output.images[0]
# 
#         # Convert to PIL Image
#         pil_image = Image.fromarray((image / 2 + 0.5).clamp(0, 1).detach().cpu().numpy().transpose(1, 2, 0) * 255).convert('RGB')
# 
#         # Display the image
#         st.image(pil_image, caption='Generated Image', use_column_width=True)
# 
#         # Provide a download button
#         buf = io.BytesIO()
#         pil_image.save(buf, format="PNG")
#         byte_im = buf.getvalue()
#         st.download_button(
#             label="Download Image",
#             data=byte_im,
#             file_name="generated_image.png",
#             mime="image/png"
#         )
# 
#     # Record and display time taken
#     end_time = time.time()
#     st.write(f"Time taken to generate image: {end_time - start_time:.2f} seconds")
# 
# st.write("Enter a textual prompt and press generate to create an image.")

"""# Launching app"""

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app_1.py
# # Paste the entire content of the updated script here



!streamlit run app_1.py &>/dev/null&

# Start an HTTP tunnel on the default port 8501 for Streamlit
url = ngrok.connect(8501)
print("Access your Streamlit app at:", url)

# you will get url after running it

# ngrok.disconnect(url)

active_tunnels = ngrok.get_tunnels()
print(active_tunnels)

ngrok.kill()

